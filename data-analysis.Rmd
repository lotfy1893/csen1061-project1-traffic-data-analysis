---
title: Traffic Data Analysis
output: html_document
---
# Importing needed libraries

```{r}
library(rmarkdown)
library(dplyr)
```
# Loading and Processing Data

We loaded the traffic-data.csv file to the R console to read it and start discovering the basic properties

```{r}
traffic_data<- read.csv("traffic-data.csv",header=TRUE)
dim(traffic_data)
```

The traffic dataset we have got about 429982 rows and 34 variables as columns, when we look at the data we will find that the first thing to do is to eliminate the advertisement columns as it has nothing relevant to our data investigation.

We can make use of the **dplyr** library verbs to eliminate certain columns with the method select(), from the dataset we can see that we have 13 columns concerning advertisement to be eliminated.

```{r}
head(traffic_data %>% select(starts_with("ad")))
grep("ad", colnames(traffic_data))
traffic_roads<-traffic_data %>% select(-starts_with("ad"))
```
Now we can find the columns that has values with zero variance or in other words has only one unique values to remove it from our dataframe.

```{r}
sapply(traffic_roads,function(x) length(unique(x))==1)
```

We find that TRUE values reside under two columns in the dataframe which are **rd.cl** and **rd.rp.type**, so we can filter these two variables.

```{r}
var.in<-c("rd.cl","rd.rp.type")
var.out<-setdiff(names(traffic_roads),var.in)
traffic_roads<-traffic_roads[var.out]
head(traffic_roads)
```
The thing also I found it useful is to use the **strptime** function to re-formata the crawl_date variable by replacing the abbreviated day-month format with a full Y%M%D format.

```{r}
traffic_roads$crawl_date <- strptime(traffic_roads$crawl_date, format = "%a %b %e %X UTC %Y", tz = "UTC") %>% as.POSIXct()
head(traffic_roads)
```

After showing the columns I noticed that we have image columns like **rd.img** which has 300k NA values out of 400k and also we have another 2 img columns **rd.rp.img** and **rd.rp.rpImg**, we cannot make use of such columns so we included those 3 variables in the elimination process as a part of the data-cleaning.

```{r}
sum(is.na(traffic_roads$rd.img))
traffic_roads<-traffic_roads %>% select(-ends_with(".img"))
dim(traffic_roads)
head(traffic_roads)
traffic_roads<-traffic_roads %>% select(-ends_with(".rpImg"))
```

When we take a good look at how the data keeps track of the reports time, we see that we only can use **crawl_date** and **rd.rp.hr/rd.rp.mn** and none of them tells the real exact time the report took place, so thats why we needed to combine the hours and minutes together first in one column in a time format and subtract from the time exists in crawl_date we get the real report's time.

```{r}
rmins<- traffic_roads["rd.rp.mn"]
rhours<- traffic_roads["rd.rp.hr"]
hours_vector<-as.vector(rhours$rd.rp.hr)
minutes_vector<-as.vector(rmins$rd.rp.mn)
report_timestamp<- paste(hours_vector,":",minutes_vector,":00",sep="")
```

Then I used a library called **chron** to convert strings of time to real time type and format.

```{r}
library(chron)
?chron
conversion <- chron(times=report_timestamp)
traffic_roads$rp.realTime <- conversion
```
